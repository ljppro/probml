{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa5c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We illustrate multicollinearity using the example in sec 6.1  of\n",
    "# [Statistical Rethinking ed 2](https://xcelab.net/rm/statistical-rethinking/).\n",
    "# The numpyro code is from [Du Phan's site]\n",
    "# (https://fehiepsi.github.io/rethinking-numpyro/06-the-haunted-dag-and-the-causal-terror.html)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    %pip install pandas\n",
    "    import pandas as pd\n",
    "\n",
    "import jax\n",
    "\n",
    "print(\"jax version {}\".format(jax.__version__))\n",
    "print(\"jax backend {}\".format(jax.lib.xla_bridge.get_backend().platform))\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap\n",
    "\n",
    "rng_key = random.PRNGKey(0)\n",
    "rng_key, rng_key_ = random.split(rng_key)\n",
    "\n",
    "try:\n",
    "    import numpyro\n",
    "except:\n",
    "    %pip install numpyro\n",
    "    import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.distributions import constraints\n",
    "from numpyro.distributions.transforms import AffineTransform\n",
    "from numpyro.diagnostics import hpdi, print_summary\n",
    "from numpyro.infer import Predictive\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "from numpyro.infer import SVI, Trace_ELBO, init_to_value\n",
    "from numpyro.infer.autoguide import AutoLaplaceApproximation\n",
    "import numpyro.optim as optim\n",
    "\n",
    "\n",
    "try:\n",
    "    import arviz as az\n",
    "except:\n",
    "    %pip install arviz\n",
    "    import arviz as az\n",
    "\n",
    "import probml_utils as pml\n",
    "\n",
    "# Data\n",
    "\n",
    "\n",
    "def sample_data1():\n",
    "    N = 100  # number of individuals\n",
    "    with numpyro.handlers.seed(rng_seed=909):\n",
    "        # sim total height of each\n",
    "        height = numpyro.sample(\"height\", dist.Normal(10, 2).expand([N]))\n",
    "        # leg as proportion of height\n",
    "        leg_prop = numpyro.sample(\"prop\", dist.Uniform(0.4, 0.5).expand([N]))\n",
    "        # sim right leg as proportion + error\n",
    "        leg_right = leg_prop * height + numpyro.sample(\"right_error\", dist.Normal(0, 0.02).expand([N]))\n",
    "        # sim left leg as proportion + error\n",
    "        leg_left = leg_prop * height + numpyro.sample(\"left_error\", dist.Normal(0, 0.02).expand([N]))\n",
    "        # combine into data frame\n",
    "        d = pd.DataFrame({\"height\": height, \"leg_left\": leg_left, \"leg_right\": leg_right})\n",
    "\n",
    "        return d\n",
    "\n",
    "\n",
    "def sample_data2():\n",
    "    N = 100  # number of individuals\n",
    "    # sim total height of each\n",
    "    height = dist.Normal(10, 2).sample(random.PRNGKey(0), (N,))\n",
    "    # leg as proportion of height\n",
    "    leg_prop = dist.Uniform(0.4, 0.5).sample(random.PRNGKey(1), (N,))\n",
    "    # sim left leg as proportion + error\n",
    "    leg_left = leg_prop * height + dist.Normal(0, 0.02).sample(random.PRNGKey(2), (N,))\n",
    "    # sim right leg as proportion + error\n",
    "    leg_right = leg_prop * height + dist.Normal(0, 0.02).sample(random.PRNGKey(3), (N,))\n",
    "    # combine into data frame\n",
    "    d = pd.DataFrame({\"height\": height, \"leg_left\": leg_left, \"leg_right\": leg_right})\n",
    "    return d\n",
    "\n",
    "\n",
    "df = sample_data2()\n",
    "\n",
    "# Model\n",
    "\n",
    "\n",
    "def model_book(leg_left, leg_right, height, br_positive=False):\n",
    "    a = numpyro.sample(\"a\", dist.Normal(10, 100))\n",
    "    bl = numpyro.sample(\"bl\", dist.Normal(2, 10))\n",
    "    if br_positive:\n",
    "        br = numpyro.sample(\"br\", dist.TruncatedNormal(0, 2, 10))\n",
    "    else:\n",
    "        br = numpyro.sample(\"br\", dist.Normal(2, 10))\n",
    "    sigma = numpyro.sample(\"sigma\", dist.Exponential(1))\n",
    "    mu = a + bl * leg_left + br * leg_right\n",
    "    numpyro.sample(\"height\", dist.Normal(mu, sigma), obs=height)\n",
    "\n",
    "\n",
    "def model_vague_prior(leg_left, leg_right, height, br_positive=False):\n",
    "    # we modify the priors to make them less informative\n",
    "    a = numpyro.sample(\"a\", dist.Normal(0, 100))\n",
    "    bl = numpyro.sample(\"bl\", dist.Normal(0, 100))\n",
    "    if br_positive:\n",
    "        br = numpyro.sample(\"br\", dist.TruncatedNormal(0, 0, 100))\n",
    "    else:\n",
    "        br = numpyro.sample(\"br\", dist.Normal(0, 100))\n",
    "    sigma = numpyro.sample(\"sigma\", dist.Exponential(1))\n",
    "    mu = a + bl * leg_left + br * leg_right\n",
    "    numpyro.sample(\"height\", dist.Normal(mu, sigma), obs=height)\n",
    "\n",
    "\n",
    "model = model_vague_prior\n",
    "\n",
    "# Analyse posterior\n",
    "\n",
    "\n",
    "def analyze_post(post, method):\n",
    "    print_summary(post, 0.95, False)\n",
    "    fig, ax = plt.subplots()\n",
    "    az.plot_forest(post, hdi_prob=0.95, figsize=(10, 4), ax=ax)\n",
    "    plt.title(method)\n",
    "    pml.savefig(f\"multicollinear_forest_plot_{method}.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    # post = m6_1.sample_posterior(random.PRNGKey(1), p6_1, (1000,))\n",
    "    fig, ax = plt.subplots()\n",
    "    az.plot_pair(post, var_names=[\"br\", \"bl\"], scatter_kwargs={\"alpha\": 0.1}, ax=ax)\n",
    "    pml.savefig(f\"multicollinear_joint_post_{method}.pdf\")\n",
    "    plt.title(method)\n",
    "    plt.show()\n",
    "\n",
    "    sum_blbr = post[\"bl\"] + post[\"br\"]\n",
    "    fig, ax = plt.subplots()\n",
    "    az.plot_kde(sum_blbr, label=\"sum of bl and br\", ax=ax)\n",
    "    plt.title(method)\n",
    "    pml.savefig(f\"multicollinear_sum_post_{method}.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Laplace fit\n",
    "\n",
    "m6_1 = AutoLaplaceApproximation(model)\n",
    "svi = SVI(\n",
    "    model,\n",
    "    m6_1,\n",
    "    optim.Adam(0.1),\n",
    "    Trace_ELBO(),\n",
    "    leg_left=df.leg_left.values,\n",
    "    leg_right=df.leg_right.values,\n",
    "    height=df.height.values,\n",
    "    br_positive=False,\n",
    ")\n",
    "svi_run = svi.run(random.PRNGKey(0), 2000)\n",
    "p6_1 = svi_run.params\n",
    "losses = svi_run.losses\n",
    "post_laplace = m6_1.sample_posterior(random.PRNGKey(1), p6_1, (1000,))\n",
    "\n",
    "analyze_post(post_laplace, \"laplace\")\n",
    "\n",
    "\n",
    "# MCMC fit\n",
    "# code from p298 (code 9.28) of rethinking2\n",
    "# https://fehiepsi.github.io/rethinking-numpyro/09-markov-chain-monte-carlo.html\n",
    "\n",
    "\n",
    "kernel = NUTS(\n",
    "    model,\n",
    "    init_strategy=init_to_value(values={\"a\": 10.0, \"bl\": 0.0, \"br\": 0.1, \"sigma\": 1.0}),\n",
    ")\n",
    "mcmc = MCMC(kernel, num_warmup=500, num_samples=500, num_chains=4)\n",
    "# df.T has size 3x100\n",
    "data_dict = dict(zip(df.columns, df.T.values))\n",
    "data_dict[\"br_positive\"] = False\n",
    "mcmc.run(random.PRNGKey(0), **data_dict)\n",
    "\n",
    "mcmc.print_summary()\n",
    "post_hmc = mcmc.get_samples()\n",
    "analyze_post(post_hmc, \"hmc\")\n",
    "\n",
    "# Constrained model where beta_r >= 0\n",
    "\n",
    "data_dict = dict(zip(df.columns, df.T.values))\n",
    "data_dict[\"br_positive\"] = True\n",
    "mcmc.run(random.PRNGKey(0), **data_dict)\n",
    "\n",
    "mcmc.print_summary()\n",
    "post_hmc = mcmc.get_samples()\n",
    "analyze_post(post_hmc, \"hmc_br_pos\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
